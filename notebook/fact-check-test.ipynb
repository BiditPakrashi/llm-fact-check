{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get your [OpenAI API Key](https://platform.openai.com/account/api-keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OpenAIChat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m q \u001b[39m=\u001b[39m  \u001b[39m\"\u001b[39m\u001b[39mis it true \u001b[39m\u001b[39m'\u001b[39m\u001b[39m The US Under Secretary of State testified that the United States supports Ukrainian biological research facilities which are institutions for scientific research to achieve scientific breakthroughs like the production of vaccines that combat major diseases. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39m#q ='\" ”'\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#q = 'is it true Albert Einstein said, \"The only thing more dangerous than ignorance is arrogance.\"'\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m llm \u001b[39m=\u001b[39m  OpenAIChat(temperature\u001b[39m=\u001b[39m\u001b[39m0.7\u001b[39m)\n\u001b[1;32m      5\u001b[0m template \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39m{question}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m      6\u001b[0m prompt_template \u001b[39m=\u001b[39m PromptTemplate(input_variables\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m\"\u001b[39m], template\u001b[39m=\u001b[39mtemplate)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OpenAIChat' is not defined"
     ]
    }
   ],
   "source": [
    "q =  \"is it true ' The US Under Secretary of State testified that the United States supports Ukrainian biological research facilities which are institutions for scientific research to achieve scientific breakthroughs like the production of vaccines that combat major diseases. '\"\n",
    "#q ='\" ”'\n",
    "#q = 'is it true Albert Einstein said, \"The only thing more dangerous than ignorance is arrogance.\"'\n",
    "llm =  OpenAIChat(temperature=0.7)\n",
    "template = \"\"\"{question}\\n\\n\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"question\"], template=template)\n",
    "question_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "template = \"\"\"Here is a statement:\n",
    "{statement}\n",
    "Make a bullet point list of the assumptions you made when producing the above statement.\\n\\n\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"statement\"], template=template)\n",
    "assumptions_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "template = \"\"\"Here is a bullet point list of assertions:\n",
    "{assertions}\n",
    "For each assertion, determine whether it is true or false. If it is false, explain why.\\n\\n\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"assertions\"], template=template)\n",
    "fact_checker_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "template = \"\"\"In light of the above facts, how would you answer the question '{}'\"\"\".format(q)\n",
    "template = \"\"\"{facts}\\n\"\"\" + template\n",
    "prompt_template = PromptTemplate(input_variables=[\"facts\"], template=template)\n",
    "answer_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[question_chain, assumptions_chain, fact_checker_chain, answer_chain], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is it true ' The US Under Secretary of State testified that the United States supports Ukrainian biological research facilities which are institutions for scientific research to achieve scientific breakthroughs like the production of vaccines that combat major diseases. '\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mAs an AI language model, I cannot confirm the current accuracy of this statement. However, according to a news article from the US Department of State on September 3, 2020, Under Secretary of State for Arms Control and International Security Affairs, Ambassador Bonnie Jenkins, expressed support for Ukraine's efforts to develop and strengthen its biological research capabilities during her visit to Ukraine. She also noted the importance of such facilities for the development of vaccines and treatments against infectious diseases.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m1. The AI language model is not capable of independently verifying the accuracy of the statement.\n",
      "2. The US Department of State issued a news article on September 3, 2020.\n",
      "3. Ambassador Bonnie Jenkins is the Under Secretary of State for Arms Control and International Security Affairs.\n",
      "4. Ambassador Jenkins visited Ukraine.\n",
      "5. Ukraine is making efforts to develop and strengthen its biological research capabilities.\n",
      "6. Such facilities are important for the development of vaccines and treatments against infectious diseases.\u001b[0m\n",
      "\u001b[38;5;200m\u001b[1;3m1. True - as an AI language model, it cannot independently verify the accuracy of any statement without external sources.\n",
      "2. True - this can be easily verified through a search engine or by visiting the US Department of State's website.\n",
      "3. False - as of 2021, Ambassador Bonnie Jenkins is not the Under Secretary of State for Arms Control and International Security Affairs. She was nominated for the position by President Biden in April 2021 but has not yet been confirmed by the Senate.\n",
      "4. True - this can be verified through news articles or official statements from the US Department of State or the Ukrainian government.\n",
      "5. True - Ukraine has publicly stated its commitment to developing its biological research capabilities, including in the field of biotechnology and biosafety. This can be verified through official Ukrainian government documents and statements.\n",
      "6. True - the development of vaccines and treatments against infectious diseases is one of the key benefits of having strong biological research capabilities. This is a well-established fact in the scientific community.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mIt is unclear if the US Under Secretary of State specifically testified to this statement. However, it is true that the US government has expressed support for Ukrainian biological research facilities and the development of vaccines to combat major diseases.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'It is unclear if the US Under Secretary of State specifically testified to this statement. However, it is true that the US government has expressed support for Ukrainian biological research facilities and the development of vaccines to combat major diseases.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(q)\n",
    "overall_chain.run(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.api.prompt import API_RESPONSE_PROMPT\n",
    "from langchain.chains import APIChain\n",
    "from langchain.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.python import PythonREPL\n",
    "from langchain.chat_models import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def check_fact_google(statement: str) -> str:\n",
    "    \"\"\"Returns If the  statement given as parameter is not empty \n",
    "    and returns true or false or partly false using  factchain. \n",
    "    If APIChain response is Empty then use other tool \"\"\"\n",
    "    llm = OpenAI(temperature=0)\n",
    "    api_key = os.environ['API_KEY']\n",
    "    factchain = APIChain.from_llm_and_api_docs(llm,factapidoc.GOOGLEFACT_DOCS, verbose=True)\n",
    "    return factchain.run(f\"Check if it is true for {statement} use  api_key like {api_key}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_fact_google(\"Clinton, Bush, Obama, Biden and Pence all took classified documents after leaving White House\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"wikipedia\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def check_claim_chain(claim) -> str:\n",
    "    \"\"\"  This tool be used to break claims in assumtions \\\n",
    "    Returns  Statement is final statement after fact check  \\  \n",
    "        The input should always be  claim as string, \\\n",
    "        and this function will always looks into the claim then  \\\n",
    "    Make a bullet point list of the assumptions \\\n",
    "        Take every assumtion and do fact check\\\n",
    "        fact check will be outside this function.\n",
    "        Fact check will be done by other tool\"\"\"\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    template = \"\"\"{question}\\n\\n\"\"\"\n",
    "    prompt_template = PromptTemplate(input_variables=[\"question\"], template=template)\n",
    "    question_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "    template = \"\"\"Here is a statement:\n",
    "    {statement}\n",
    "    Make a bullet point list of the assumptions you made when producing the above statement.\\n\\n\"\"\"\n",
    "    prompt_template = PromptTemplate(input_variables=[\"statement\"], template=template)\n",
    "    assumptions_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "    template = \"\"\"Here is a bullet point list of assertions:\n",
    "    {assertions}\n",
    "    For each assertion, determine whether it is true or false. If it is false, explain why.\\n\\n\"\"\"\n",
    "    prompt_template = PromptTemplate(input_variables=[\"assertions\"], template=template)\n",
    "    fact_checker_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "    template = f\"\"\"In light of the above facts, how would you answer the question '{claim}'\"\"\"\n",
    "    template = \"\"\"{facts}\\n\"\"\" + template\n",
    "    prompt_template = PromptTemplate(input_variables=[\"facts\"], template=template)\n",
    "    answer_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "    overall_chain = SimpleSequentialChain(chains=[question_chain, assumptions_chain, fact_checker_chain, answer_chain], verbose=True)\n",
    "    \n",
    "    return overall_chain.run(claim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent= initialize_agent(\n",
    "    tools + [check_claim_chain , check_fact_google] , \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: This is a historical fact-checking question, we can use Wikipedia to confirm the dates of Franklin D. Roosevelt's presidency and cross-check it with the timeline of World War 1.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"Franklin D. Roosevelt presidency\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Presidency of Franklin D. Roosevelt\n",
      "Summary: For the presidency of Franklin D. Roosevelt, see:\n",
      "\n",
      "Presidency of Franklin D. Roosevelt, first and second terms (1933–1937 and 1937–1941), as U.S. president\n",
      "Presidency of Franklin D. Roosevelt, third and fourth terms (1941–1945 and January–April 1945), as U.S. president\n",
      "\n",
      "\n",
      "\n",
      "Page: Presidency of Franklin D. Roosevelt, third and fourth terms\n",
      "Summary: The third presidential term of Franklin D. Roosevelt began on January 20, 1941, when he was once again inaugurated as the 32nd president of the United States, and the fourth term of his presidency ended with his death on April 12, 1945. Roosevelt won a third term by defeating Republican nominee Wendell Willkie in the 1940 United States presidential election. He remains the only president to serve for more than two terms. Unlike his first two terms, Roosevelt's third and fourth terms were dominated by foreign policy concerns, as the United States became involved in World War II in December 1941.\n",
      "Roosevelt won congressional approval of the Lend-Lease program, which was designed to aid the United Kingdom in its war against Nazi Germany, while the US remained officially neutral. After Germany began war against the Soviet Union in June 1941, Roosevelt extended Lend-Lease to the Soviet Union as well. In Asia, Roosevelt provided aid to the Republic of China, which was resisting an invasion by the Empire of Japan. In response to the July 1941 Japanese occupation of French Indochina, Roosevelt expanded a trade embargo to cut off oil that Japan urgently needed for its fleet. When Roosevelt refused to end the embargo, on December 7, 1941, Japan launched an attack on the U.S. fleet stationed at Pearl Harbor in Hawaii. Isolationist sentiment in the US immediately collapsed and Congress declared war on Japan. After Germany declared war on the US, Congress declared war on it and Italy. To win the war, the US, Britain and USSR assembled a large coalition of Allied Powers.  The U.S. funded much of the war efforts of the other allies, and supplied munitions, food, and oil. In consultation with his Army and Navy and British Prime Minister Winston Churchill, Roosevelt decided on a Europe first strategy, which focused on defeating Germany before Japan. In practice, however, in 1942 and 1943 the U.S. focused on fighting Japan.\n",
      "In late 1942 U.S. began its ground campaign against Germany with an invasion of North Africa. The German and Italian forces surrendered in May 1943, opening the way for the invasions of Sicily and Italy. Meanwhile, the U.S. Navy won a decisive victory over Japan in the Battle of Midway and began a campaign of island hopping in the Pacific. In 1943, the Allies launched an invasion of Italy and continued to pursue the island hopping strategy. The top Allied leaders met at the Tehran Conference in 1943, where they began to discuss post-war plans. Among the concepts discussed was the United Nations, an intergovernmental organization championed by Roosevelt that would replace the League of Nations after the war. In 1944, the U.S. launched a successful invasion of northern France and won a decisive naval victory over Japan in the Battle of Leyte Gulf. By the time of Roosevelt's death in April 1945, the U.S. had occupied portions of Germany and was in the process of capturing Okinawa. Germany and Japan surrendered in May–August 1945 during the administration of Roosevelt's successor Harry S. Truman, who previously served as Roosevelt's Vice President.\n",
      "Though foreign affairs dominated Roosevelt's third and fourth terms, important developments also took place on the home front. The military buildup spurred economic growth, and unemployment fell precipitously. The United States excelled at war production; in 1944, it produced more military aircraft than the combined output of Germany, Japan, Britain, and the Soviet Union. The United States also established the Manhattan Project to produce the world's first nuclear weapons. As in Roosevelt's sec\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mBased on the information from Wikipedia, Franklin D. Roosevelt was not the president during World War 1, but rather during World War 2. We can confirm this by double-checking the dates of World War 1.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"World War 1\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: World War I\n",
      "Summary: World War I or the First World War (28 July 1914 – 11 November 1918), often abbreviated as WWI, was one of the deadliest global conflicts in history. It was fought between two coalitions, the Allies and the Central Powers. Fighting occurred throughout Europe, the Middle East, Africa, the Pacific, and parts of Asia. An estimated 9 million soldiers were killed in combat, plus another 23 million wounded, while 5 million civilians died as a result of military action, hunger, and disease. Millions more died as a result of genocide, while the 1918 Spanish flu pandemic was exacerbated by the movement of combatants during the war.\n",
      "The first decade of the 20th century saw increasing diplomatic tension between the European great powers. This reached a breaking point on 28 June 1914, when a Bosnian Serb named Gavrilo Princip assassinated Archduke Franz Ferdinand, heir to the Austro-Hungarian throne. Austria-Hungary held Serbia responsible, and declared war on 28 July. Russia came to Serbia's defence, and by 4 August, defensive alliances had drawn in Germany, France, and Britain, with the Ottoman Empire joining the war in November.\n",
      "German strategy in 1914, known as the Schlieffen Plan, was to first defeat France and bypass their fortifications by moving through Belgium, then attack Russia. However, this manoeuvre failed due to heavy French and Belgian resistance, and British reinforcements. By the end of 1914, the Western Front consisted of a continuous line of trenches stretching from the English Channel to Switzerland. The Eastern Front was more fluid, but neither side could gain a decisive advantage, despite a series of costly offensives. Fighting expanded onto secondary fronts as Bulgaria, Romania, Greece, and most notably Italy, and others entered the war between 1915 and 1916.\n",
      "The United States entered the war on the side of the Allies in April 1917, while the Bolsheviks seized power in the Russian October Revolution, and made peace with the Central Powers in early 1918. Freed from the Eastern Front, Germany launched an offensive in the west on March 1918, hoping to achieve a decisive victory before American troops arrived in significant numbers. Failure left the German Imperial Army exhausted and demoralised, and when the Allies took the offensive in August 1918, German forces could not stop the advance.\n",
      "Between 29 September and 3 November 1918, Bulgaria, the Ottoman Empire, and Austria-Hungary agreed to armistices with the Allies, leaving Germany isolated. Facing revolution at home, and with his army on the verge of mutiny, Kaiser Wilhelm II abdicated on 9 November. The Armistice of 11 November 1918 brought the fighting to a close, while the Paris Peace Conference imposed various settlements on the defeated powers, the best-known being the Treaty of Versailles. The dissolution of the Russian, German, Austro-Hungarian, and Ottoman Empires resulted in the creation of new independent states, among them Poland, Czechoslovakia, and Yugoslavia. Failure to manage the instability that resulted from this upheaval during the interwar period contributed to the outbreak of World War II in September 1939.\n",
      "\n",
      "Page: Causes of World War I\n",
      "Summary: The identification of the causes of World War I remains controversial. World War I began in the Balkans on July 28, 1914, and hostilities ended on November 11, 1918, leaving 17 million dead and 25 million wounded. Moreover, the Russian Civil War can in many ways be considered a continuation of World War I, as can various other conflicts in the direct aftermath of 1918.\n",
      "Scholars looking at the long term seek to explain why two rival sets of powers (the German Empire and Austria-Hungary against the Russian Empire, France, the British Empire and later the United States) came into conflict by 1915. They look at such factors as political, territorial and economic competition; militarism, a complex web of alliances and alignments; imperialism, the growth of nationalism; and the power \u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: Franklin D. Roosevelt was NOT president during World War 1. He was president during World War 2.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Franklin D. Roosevelt was president during ww1',\n",
       " 'output': 'Franklin D. Roosevelt was NOT president during World War 1. He was president during World War 2.'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"Franklin D. Roosevelt was president during ww1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent(\"Clinton, Bush, Obama, Biden and Pence all took classified documents after leaving White House\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "\n",
    "search = GoogleSearchAPIWrapper()\n",
    "def top5_results(query):\n",
    "    return search.results(query, 5)\n",
    "\n",
    "tool = Tool(\n",
    "    name = \"Google Search\",\n",
    "    description=\"Search Google for recent results.\",\n",
    "    func=top5_results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Obama birth certificate, White House',\n",
       "  'link': 'https://obamawhitehouse.archives.gov/sites/default/files/rss_viewer/birth-certificate-long-form.pdf',\n",
       "  'snippet': \"STATE OF HAWAII. 1 Child's First Name. (Type or print). BARACK. CERTIFICATE OF LIVE BIRTH lb. Middle Name. HUSSE. HUSSEIN. FILE. NUMBER 151.\"},\n",
       " {'title': 'Barack Obama - Wikipedia',\n",
       "  'link': 'https://en.wikipedia.org/wiki/Barack_Obama',\n",
       "  'snippet': 'Barack Hussein Obama II is an American politician who served as the 44th president of the United States from 2009 to 2017. A member of the Democratic Party,\\xa0...'},\n",
       " {'title': \"What is Obama's first name? - Quora\",\n",
       "  'link': 'https://www.quora.com/What-is-Obamas-first-name',\n",
       "  'snippet': 'His full name is Barack Hussein Obama II. Since the “II” is simply because he was named for his father, his last name is Obama.'},\n",
       " {'title': 'Growing Up Barack: Meet Three Boys Named After President Obama',\n",
       "  'link': 'https://www.nbcnews.com/storyline/president-obama-the-legacy/growing-barack-meet-three-boys-named-after-president-obama-n709046',\n",
       "  'snippet': 'Jan 19, 2017 ... Jordan Barack Treasure, New York City, born in 2008 ... Jordan Barack Treasure made national news when he was the focus of a New York newspaper\\xa0...'},\n",
       " {'title': 'When Barry Became Barack',\n",
       "  'link': 'https://www.newsweek.com/when-barry-became-barack-84255',\n",
       "  'snippet': \"Mar 22, 2008 ... Barry Obama decided that he didn't like his nickname. A few of his friends at Occidental College had already begun to call him Barack (his\\xa0...\"}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.run(\"Obama's first name?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "factcheck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
